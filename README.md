# Log Sentinel AI ğŸ›¡ï¸ğŸ”

### Um analisador de logs inteligente com o poder do Google Gemini para transformar dados tÃ©cnicos em insights de seguranÃ§a acionÃ¡veis.

![GIF do Log Sentinel AI em AÃ§Ã£o](https://github.com/Kaue-Lustosa/log-sentinel-ai/blob/main/demo/first_view.gif)

---

## ğŸš€ Sobre o Projeto

O **Log Sentinel AI** Ã© uma aplicaÃ§Ã£o web full-stack projetada para auxiliar analistas de seguranÃ§a, profissionais de forense digital e desenvolvedores a entender rapidamente logs de sistema complexos. Em um cenÃ¡rio de resposta a incidentes, cada segundo conta. Esta ferramenta utiliza um Large Language Model (LLM) para traduzir logs enigmÃ¡ticos, avaliar riscos, extrair Indicadores de Comprometimento (IoCs) e sugerir aÃ§Ãµes prÃ¡ticas, tudo em tempo real.

Este projeto foi desenvolvido como um case de estudo aprofundado na integraÃ§Ã£o de InteligÃªncia Artificial com CiberseguranÃ§a, demonstrando habilidades em desenvolvimento de software, arquitetura de sistemas e engenharia de prompts.

**ğŸ”— Teste a aplicaÃ§Ã£o ao vivo:** [URL_DA_SUA_APLICAÃ‡ÃƒO_NA_VERCEL]

---

## âœ¨ Funcionalidades Principais

* **AnÃ¡lise com IA:** Utiliza a API do Google Gemini para fornecer uma anÃ¡lise contextual de logs.
* **TraduÃ§Ã£o e Risco:** Converte logs tÃ©cnicos em linguagem humana e atribui um nÃ­vel de risco (de Informativo a CrÃ­tico).
* **ExtraÃ§Ã£o de IoCs:** Identifica e extrai automaticamente IPs, domÃ­nios, hashes e URLs.
* **Chunking Inteligente:** Suporta logs de grande volume, dividindo-os em pedaÃ§os para uma anÃ¡lise completa sem exceder os limites da IA.
* **Interface Reativa:** Frontend moderno e responsivo construÃ­do com Next.js e Tailwind CSS.

---

## ğŸ› ï¸ Tecnologias Utilizadas

| Frontend | Backend | IA & Bibliotecas | ImplantaÃ§Ã£o (Deployment) |
| :--- | :--- | :--- | :--- |
| Next.js | Python 3 | Google Gemini API | Vercel |
| React | FastAPI | LangChain | Render |
| TypeScript | Pydantic | - | - |
| Tailwind CSS | - | - | - |
| Shadcn/UI | - | - | - |
| Framer Motion| - | - | - |

---

## âš™ï¸ Como Executar Localmente

Siga os passos abaixo para configurar e executar o projeto em sua mÃ¡quina local.

### PrÃ©-requisitos

* Node.js (v18+)
* Python (v3.9+)
* Uma chave de API do Google AI Studio

### Backend (FastAPI)

1.  **Navegue atÃ© a pasta do backend:**
    ```bash
    cd backend
    ```
2.  **Crie e ative um ambiente virtual:**
    ```bash
    python -m venv venv
    source venv/bin/activate # ou venv\Scripts\activate no Windows
    ```
3.  **Instale as dependÃªncias:**
    ```bash
    pip install -r requirements.txt # (Lembre-se de criar este arquivo com 'pip freeze > requirements.txt')
    ```
4.  **Configure as variÃ¡veis de ambiente:**
    * Crie um arquivo `.env` na pasta `backend`.
    * Adicione sua chave de API: `GOOGLE_API_KEY="SUA_CHAVE_AQUI"`
5.  **Inicie o servidor:**
    ```bash
    uvicorn main:app --reload
    ```
    O backend estarÃ¡ rodando em `http://localhost:8000`.

### Frontend (Next.js)

1.  **Navegue atÃ© a pasta do frontend:**
    ```bash
    cd frontend
    ```
2.  **Instale as dependÃªncias:**
    ```bash
    npm install
    ```
3.  **Inicie o servidor de desenvolvimento:**
    ```bash
    npm run dev
    ```
    A aplicaÃ§Ã£o estarÃ¡ acessÃ­vel em `http://localhost:3000`.

---

## ğŸ‘¨â€ğŸ’» Desenvolvido por

**KauÃª Lustosa Morgado**

* **LinkedIn:** https://www.linkedin.com/in/kauÃª-lustosa/
* **GitHub:** [https://github.com/Kaue-Lustosa]
